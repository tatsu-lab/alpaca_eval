Yi-34B-Chat:
  prompt_template: "Yi-34B-Chat/prompt.txt"
  fn_completions: "huggingface_local_completions"
  completions_kwargs:
    model_name: "01-ai/Yi-34b-Chat"
    model_kwargs:
      torch_dtype: "bfloat16"
    max_new_tokens: 3500
    temperature: 0.3
    top_p: 0.8
    do_sample: True
    is_fast_tokenizer: False
    eos_token_id: [7]
    batch_size: 5
  pretty_name: "Yi-34B-Chat"
  link: "https://huggingface.co/01-ai/Yi-34B-Chat"

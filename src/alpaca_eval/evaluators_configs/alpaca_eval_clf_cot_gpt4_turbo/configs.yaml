alpaca_eval_clf_cot_gpt4_turbo:
  prompt_template: "alpaca_eval_clf_cot_gpt4_turbo/alpaca_eval_clf_cot.txt"
  fn_completions: "openai_completions"
  completions_kwargs:
    model_name: "gpt-4-1106-preview"
    max_tokens: 300
    temperature: 1 # temperature should be applied for sampling, so that should make no effect.
    logprobs: true
    top_logprobs: 5
  fn_completion_parser: "logprob_parser"
  completion_parser_kwargs:
    numerator_token: "m"
    denominator_tokens: ["m", "M"]
    is_binarize: true
    log_prob_index: -1
  completion_key: "completions_all"
  batch_size: 1
  processors_to_kwargs:
    ChainOfThoughtProcessor: {}
